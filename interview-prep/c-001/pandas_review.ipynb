{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Capital One Technical Interview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical & Design Interview Guidelines\n",
    "\n",
    "For the **Technical** Interview: Building end-to-end data pipelines with pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "DATA_FILEPATH = r\"../../data/beijing_airquality/PRSA_Data_Changping_20130301-20170228.csv\"\n",
    "\n",
    "# data = pd.read_csv(DATA_FILEPATH, chunksize=10000, header=0, index_col='No', on_bad_lines='warn')\n",
    "df = pd.read_csv(DATA_FILEPATH, header=0, index_col='No', on_bad_lines='warn')\n",
    "\n",
    "# display(df)\n",
    "# df.info()\n",
    "# df.describe(include='all')\n",
    "df['year'].value_counts(sort=False).to_dict()\n",
    "\n",
    "# display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De-duping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rows before de-dup: {len(df.index)}\")\n",
    "print(f\"deduping... \")\n",
    "df.drop_duplicates(subset=['year', 'month', 'day', 'hour'], inplace=True, ignore_index=True, keep='last')\n",
    "print(f\"rows after de-dup: {len(df.index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "df = df.drop(columns=['PM2.5', 'SO2', 'NO2', 'O3'], errors='ignore')\n",
    "# change column names to lower case\n",
    "[df.rename(columns={col: col.lower()}, inplace=True) for col in list(df.columns) if col.isupper()]\n",
    "# check columns\n",
    "necessary_columns = ('year', 'month', 'day', 'hour', 'temp', 'pres', 'dewp', 'rain', 'wd', 'wspm', 'station')\n",
    "assert all([col in list(df.columns) for col in necessary_columns]), f\"Missing schema column\"\n",
    "# use efficient data types\n",
    "print(\"data types before cast:\")\n",
    "print(df.dtypes)\n",
    "df['year'] = pd.to_numeric(df['year'], downcast='unsigned')\n",
    "df['month'] = pd.to_numeric(df['month'], downcast='unsigned')\n",
    "df['day'] = pd.to_numeric(df['day'], downcast='unsigned')\n",
    "df['hour'] = pd.to_numeric(df['hour'], downcast='unsigned')\n",
    "df['pm10'] = pd.to_numeric(df['pm10'], downcast='float')\n",
    "df['co'] = pd.to_numeric(df['co'], downcast='float')\n",
    "df['temp'] = pd.to_numeric(df['temp'], downcast='float')\n",
    "df['pres'] = pd.to_numeric(df['pres'], downcast='float')\n",
    "df['dewp'] = pd.to_numeric(df['dewp'], downcast='float')\n",
    "df['rain'] = pd.to_numeric(df['rain'], downcast='float')\n",
    "df['wspm'] = pd.to_numeric(df['wspm'], downcast='float')\n",
    "df['wd'] = df['wd'].astype('category')\n",
    "df['station'] = df['station'].astype('category')\n",
    "print(\"data types after cast:\")\n",
    "print(df.dtypes)\n",
    "# create date\n",
    "df['mdate'] = df.apply(lambda row: datetime(year=row['year'], month=row['month'], day=row['day'], hour=row['hour']), axis='columns')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting and Handling nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum of null values\n",
    "df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display any rows with nulls\n",
    "ndf = df[df.isnull().any(axis=1)]\n",
    "# display(ndf)\n",
    "\n",
    "# filter columns\n",
    "ndf = df[['mdate', 'year', 'month', 'day', 'hour', 'temp', 'pres']]\n",
    "\n",
    "# let's looks only at the null values in temp\n",
    "ndf = ndf[ndf['temp'].isnull()]\n",
    "display(ndf)\n",
    "print(ndf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "interpolate missing temperatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns\n",
    "xdf = df[['mdate', 'year', 'month', 'day', 'hour', 'temp', 'pres']]\n",
    "\n",
    "# interpolate\n",
    "xdf.set_index('mdate', inplace=True)\n",
    "xdf['temp'] = xdf['temp'].interpolate(method='linear')\n",
    "\n",
    "# list of missing values\n",
    "filter_list = list(ndf['mdate'].unique())\n",
    "xdf = xdf.loc[filter_list]\n",
    "display(xdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using `ffill()` and `bfill()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(ndf)\n",
    "\n",
    "xdf = df[['mdate', 'year', 'month', 'day', 'hour', 'temp', 'pres']].copy()\n",
    "xdf['temp'].ffill(inplace=True)\n",
    "xdf = xdf[xdf['mdate'].isin(filter_list)]\n",
    "display(xdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# average temperature per year\n",
    "\n",
    "avg_temp = df[['year', 'temp']].groupby(['year']).agg({'temp': 'mean'})\n",
    "display(avg_temp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selection and Filtering Exercises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter columns\n",
    "xdf = df[['year', 'mdate', 'temp', 'rain']]\n",
    "xdf = xdf[xdf['year'] == 2016]\n",
    "# display(xdf.iloc[0:10, :2])\n",
    "\n",
    "# get daily average and show dates that are sub -5 degree\n",
    "gdf = df[df['year'] == 2016][['year', 'month', 'day', 'temp']]\n",
    "gdf = gdf.groupby(['year', 'month', 'day']).agg({'temp': 'mean'})\n",
    "# filter sub -3.0 degree temps\n",
    "# gdf = gdf[gdf['temp'] < -3.0]\n",
    "# with query\n",
    "gdf = gdf.query('temp < -3.0 & ~(year == 2017)')\n",
    "# gdf.reset_index(inplace=True)\n",
    "display(gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# linear plot of temperature\n",
    "vdf = df[(df['temp'].notnull()) & (df['year'] == 2016) & (df['month'] == 1)]\n",
    "# vdf = vdf[['year', 'month', 'day', 'hour', 'temp']].set_index(['year', 'month', 'day', 'hour'])\n",
    "vdf = vdf[['mdate', 'temp']].set_index('mdate')\n",
    "\n",
    "# df['temp'].plot(kind='line', title='Jan Temps')\n",
    "\n",
    "plt.plot(vdf.index, vdf['temp'], scalex=True, marker='x')\n",
    "plt.xticks(rotation=45)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Temp')\n",
    "plt.title('Jan Temperatures')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Box plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'category': ['A', 'A', 'B', 'B', 'C', 'C', 'D', 'D'],\n",
    "    'values': [1, 5, 2, 8, 3, 7, 4, 6]\n",
    "})\n",
    "\n",
    "# Create a box plot for the values grouped by category\n",
    "df.boxplot(column='values', by='category')\n",
    "plt.title('Box Plot of Values by Category')\n",
    "plt.suptitle('')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Box chart of wind direction and wind speed to see if wind is stronger in some directions in Beijing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# display(df)\n",
    "\n",
    "# check out null values\n",
    "tdf = df[(df['wd'].isnull()) | (df['wspm'].isnull())]\n",
    "null_dates = list(tdf['mdate'])\n",
    "print(f\"wind speed or direction null row count: {tdf.shape[0]}\")\n",
    "\n",
    "# interpolating wind null values\n",
    "print(\"filling null values...\")\n",
    "wdf = df.copy()\n",
    "wdf.set_index('mdate', inplace=True)\n",
    "wdf['wd'] = wdf['wd'].ffill()\n",
    "wdf['wspm'] = wdf['wspm'].interpolate(method='linear')\n",
    "print(\"showing filled values:\")\n",
    "display(wdf.loc[null_dates][:10])\n",
    "\n",
    "# print unique wind dirs\n",
    "display(list(wdf['wd'].unique()))\n",
    "\n",
    "# box chart of wind direction and speed\n",
    "df.boxplot(column='wspm', by='wd', fontsize=11)\n",
    "plt.title(\"Wind Speed and Direction\")\n",
    "plt.xlabel(\"wind direction\")\n",
    "plt.ylabel(\"wind speed (m)\")\n",
    "plt.suptitle(\"\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Heatmap\n",
    "\n",
    "Heatmap of temperatures in 2016 to see if some temperatures are more prevalent!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# display(df)\n",
    "\n",
    "# copy data and remove null temperatures\n",
    "vdf = df.set_index('mdate')[['temp', 'pres']].copy()\n",
    "# show null counts\n",
    "print(f\"null counts: {vdf.isnull().sum().to_dict()}\\t shape: {vdf.shape}\")\n",
    "print(\"removing nulls...\")\n",
    "vdf = vdf.drop(index=list(vdf[vdf['temp'].isnull()].index))\n",
    "print(f\"null counts: {vdf.isnull().sum().to_dict()}\\t shape: {vdf.shape}\")\n",
    "\n",
    "# normalizing temps\n",
    "print(\"rounding temperatures...\")\n",
    "vdf['temp'] = vdf['temp'].map(lambda x: round(x, 0))\n",
    "\n",
    "print(\"plotting...\") \n",
    "sns.heatmap(list(vdf['temp']), annot=True, cmap='coolwarm')\n",
    "plt.title(\"Beijing Temperature Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "# Create a random correlation matrix\n",
    "data = np.random.rand(10, 12)\n",
    "display(data)\n",
    "\n",
    "# Create a heatmap with Seaborn\n",
    "sns.heatmap(data, annot=True, cmap='coolwarm')\n",
    "plt.title('Heatmap of Random Data')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
