{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare for Capital One Technical Interview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical & Design Interview Guidelines\n",
    "\n",
    "For the **Technical** Interviews:\n",
    "\n",
    "  -  In the Hands-On/Coding Technical Interview, the primary focus will be walking through a code test or code review with your technical interviewer in your language of choice (This will include small functions, usage, algorithmic knowledge, etc.)\n",
    "\n",
    "       - This session will be about building a data pipeline (preferred languages for building pipeline are Python, Java, or Scala - but technically you could use anything besides SQL for this part) \n",
    "\n",
    "       - Skills tested: scrubbing data, obtaining data, cleaning data and loading data. Once the data is loaded you will need to demonstrate querying skills (for querying data you can use SQL).  \n",
    "\n",
    "       - Be prepared to solve code, and discuss your reasoning behind the way you solved it - dig deep for the interviewer\n",
    "\n",
    "  -  In the **Design** focused Technical Interview, there is a specific working problem that it will centralize around:\n",
    "\n",
    "       - Designing a data pipeline\n",
    "\n",
    "       - Items to think about: database design concepts, Schemas, data pipeline design, Design Time Vs Run Time of the stack, Designing Data Engineering Solutions at Scale, etc.. \n",
    "\n",
    "       - Be prepared to utilize the whiteboarding feature in Zoom\n",
    "\n",
    "       - Use these [System Design Primer/Topics](https://github.com/kvasukib/system-design-primer*system-design-topics-start-here) to help you prepare\n",
    "\n",
    "  -  Some general things to also think about:\n",
    "\n",
    "       - Core programming skills, design philosophy, risk factors, coding standards, etc.\n",
    "\n",
    "       - Data structures, Object oriented programming & Code optimization.\n",
    "\n",
    "       - System Design and common architectural patterns\n",
    "\n",
    "       - API Design & Data Modeling\n",
    "\n",
    "       - Design Tradeoffs & Performance tuning\n",
    "\n",
    "       - What motivates you in technology, specific languages, etc.?\n",
    "\n",
    "       - You should expect some technical questions from the interviewers related to your technical background\n",
    "\n",
    "       - What do you see as some exciting things you may be able to bring to the table at Capital One?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "DATA_FILEPATH = r\"../../data/beijing_airquality/PRSA_Data_Changping_20130301-20170228.csv\"\n",
    "\n",
    "# data = pd.read_csv(DATA_FILEPATH, chunksize=10000, header=0, index_col='No', on_bad_lines='warn')\n",
    "df = pd.read_csv(DATA_FILEPATH, header=0, index_col='No', on_bad_lines='warn')\n",
    "\n",
    "# display(df)\n",
    "# df.info()\n",
    "# df.describe(include='all')\n",
    "df['year'].value_counts(sort=False).to_dict()\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### De-duping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"rows before de-dup: {len(df.index)}\")\n",
    "print(f\"deduping... \")\n",
    "df.drop_duplicates(subset=['year', 'month', 'day', 'hour'], inplace=True, ignore_index=True, keep='last')\n",
    "print(f\"rows after de-dup: {len(df.index)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping columns\n",
    "df = df.drop(columns=['PM2.5', 'SO2', 'NO2', 'O3'], errors='ignore')\n",
    "# change column names to lower case\n",
    "[df.rename(columns={col: col.lower()}, inplace=True) for col in list(df.columns) if col.isupper()]\n",
    "# check columns\n",
    "necessary_columns = ('year', 'month', 'day', 'hour', 'temp', 'pres', 'dewp', 'rain', 'wd', 'wspm', 'station')\n",
    "assert all([col in list(df.columns) for col in necessary_columns]), f\"Missing schema column\"\n",
    "# use efficient data types\n",
    "print(\"data types before cast:\")\n",
    "print(df.dtypes)\n",
    "df['year'] = pd.to_numeric(df['year'], downcast='unsigned')\n",
    "df['month'] = pd.to_numeric(df['month'], downcast='unsigned')\n",
    "df['day'] = pd.to_numeric(df['day'], downcast='unsigned')\n",
    "df['hour'] = pd.to_numeric(df['hour'], downcast='unsigned')\n",
    "df['pm10'] = pd.to_numeric(df['pm10'], downcast='float')\n",
    "df['co'] = pd.to_numeric(df['co'], downcast='float')\n",
    "df['temp'] = pd.to_numeric(df['temp'], downcast='float')\n",
    "df['pres'] = pd.to_numeric(df['pres'], downcast='float')\n",
    "df['dewp'] = pd.to_numeric(df['dewp'], downcast='float')\n",
    "df['rain'] = pd.to_numeric(df['rain'], downcast='float')\n",
    "df['wspm'] = pd.to_numeric(df['wspm'], downcast='float')\n",
    "df['wd'] = df['wd'].astype('category')\n",
    "df['station'] = df['station'].astype('category')\n",
    "print(\"data types after cast:\")\n",
    "print(df.dtypes)\n",
    "# create date\n",
    "df['mdate'] = df.apply(lambda row: datetime(year=row['year'], month=row['month'], day=row['day'], hour=row['hour']), axis='columns')\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting and Handling nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
